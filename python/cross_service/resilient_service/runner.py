# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

"""
How to Build and Manage a Resilient Service

This example shows how to use the AWS SDK for Python (Boto3) to create a load-balanced
web service that returns recommendations of books, movies, and songs. It demonstrates
how the service responds to failures, and shows ways to restructure the service to be
more resilient when failures occur.
"""

import demo_tools.question as q
import argparse
import logging
import sys
from pprint import pp

import requests
from auto_scaler import AutoScaler
from load_balancer import LoadBalancer
from parameters import ParameterHelper
from recommendation_service import RecommendationService

# Add relative path to include demo_tools in this code example without
# need for setup.
sys.path.append("../..")


# snippet-start:[python.example_code.workflow.ResilientService_Runner]
class Runner:
    def __init__(
            self,
            resource_path,
            recommendation,
            autoscaler,
            loadbalancer,
            param_helper):
        self.resource_path = resource_path
        self.recommendation = recommendation
        self.autoscaler = autoscaler
        self.loadbalancer = loadbalancer
        self.param_helper = param_helper
        self.protocol = "HTTP"
        self.port = 80
        self.ssh_port = 22

    def deploy(self):
        recommendations_path = f"{self.resource_path}/recommendations.json"
        startup_script = f"{self.resource_path}/server_startup_script.sh"
        instance_policy = f"{self.resource_path}/instance_policy.json"

        print(
            "\nFor this demo, we'll use the AWS SDK for Python (Boto3) to create several AWS resources\n"
            "to set up a load-balanced web service endpoint and explore some ways to make it resilient\n"
            "against various kinds of failures.\n\n"
            "Some of the resources create by this demo are:\n")
        print(
            "\t* A DynamoDB table that the web service depends on to provide book, movie, and song recommendations."
        )
        print(
            "\t* An EC2 launch template that defines EC2 instances that each contain a Python web server."
        )
        print(
            "\t* An EC2 Auto Scaling group that manages EC2 instances across several Availability Zones."
        )
        print(
            "\t* An Elastic Load Balancing (ELB) load balancer that targets the Auto Scaling group to distribute requests."
        )
        print("-" * 88)
        q.ask("Press Enter when you're ready to start deploying resources.")

        print(
            f"Creating and populating a DynamoDB table named '{self.recommendation.table_name}'."
        )
        self.recommendation.create()
        self.recommendation.populate(recommendations_path)
        print("-" * 88)

        print(
            f"Creating an EC2 launch template that runs '{startup_script}' when an instance starts.\n"
            f"This script starts a Python web server defined in the `server.py` script. The web server\n"
            f"listens to HTTP requests on port 80 and responds to requests to '/' and to '/healthcheck'.\n"
            f"For demo purposes, this server is run as the root user. In production, the best practice is to\n"
            f"run a web server, such as Apache, with least-privileged credentials.\n")
        print(
            f"The template also defines an IAM policy that each instance uses to assume a role that grants\n"
            f"permissions to access the DynamoDB recommendation table and Systems Manager parameters\n"
            f"that control the flow of the demo.\n")
        self.autoscaler.create_template(startup_script, instance_policy)
        print("-" * 88)

        print(
            f"Creating an EC2 Auto Scaling group that maintains three EC2 instances, each in a different\n"
            f"Availability Zone.")
        zones = self.autoscaler.create_group(3)
        print("-" * 88)
        print(
            "At this point, you have EC2 instances created. Once each instance starts, it listens for\n"
            "HTTP requests. You can see these instances in the console or continue with the demo.")
        print("-" * 88)
        q.ask("Press Enter when you're ready to continue.")

        print(f"Creating variables that control the flow of the demo.\n")
        self.param_helper.reset()

        print(
            "\nCreating an Elastic Load Balancing target group and load balancer. The target group\n"
            "defines how the load balancer connects to instances. The load balancer provides a\n"
            "single endpoint where clients connect and dispatches requests to instances in the group.\n")
        vpc = self.autoscaler.get_default_vpc()
        subnets = self.autoscaler.get_subnets(vpc["VpcId"], zones)
        target_group = self.loadbalancer.create_target_group(
            self.protocol, self.port, vpc["VpcId"]
        )
        self.loadbalancer.create_load_balancer(
            [subnet["SubnetId"] for subnet in subnets], target_group
        )
        self.autoscaler.attach_load_balancer_target_group(target_group)
        print(f"Verifying access to the load balancer endpoint...")
        lb_success = self.loadbalancer.verify_load_balancer_endpoint()
        if not lb_success:
            print(
                "Couldn't connect to the load balancer, verifying that the port is open..."
            )
            current_ip_address = requests.get(
                "http://checkip.amazonaws.com"
            ).text.strip()
            sec_group, port_is_open = self.autoscaler.verify_inbound_port(
                vpc, self.port, current_ip_address
            )
            sec_group, ssh_port_is_open = self.autoscaler.verify_inbound_port(
                vpc, self.ssh_port, current_ip_address
            )
            if not port_is_open:
                print(
                    "For this example to work, the default security group for your default VPC must\n"
                    "allows access from this computer. You can either add it automatically from this\n"
                    "example or add it yourself using the AWS Management Console.\n")
                if q.ask(
                    f"Do you want to add a rule to security group {sec_group['GroupId']} to allow\n"
                    f"inbound traffic on port {self.port} from your computer's IP address of {current_ip_address}? (y/n) ",
                    q.is_yesno,
                ):
                    self.autoscaler.open_inbound_port(
                        sec_group["GroupId"], self.port, current_ip_address
                    )
            if not ssh_port_is_open:
                if q.ask(
                    f"Do you want to add a rule to security group {sec_group['GroupId']} to allow\n"
                    f"inbound SSH traffic on port {self.ssh_port} for debugging from your computer's IP address of {current_ip_address}? (y/n) ",
                    q.is_yesno,
                ):
                    self.autoscaler.open_inbound_port(
                        sec_group["GroupId"], self.ssh_port, current_ip_address
                    )
            lb_success = self.loadbalancer.verify_load_balancer_endpoint()
        if lb_success:
            print("Your load balancer is ready. You can access it by browsing to:\n")
            print(f"\thttp://{self.loadbalancer.endpoint()}\n")
        else:
            print(
                "Couldn't get a successful response from the load balancer endpoint. Troubleshoot by\n"
                "manually verifying that your VPC and security group are configured correctly and that\n"
                "you can successfully make a GET request to the load balancer endpoint:\n")
            print(f"\thttp://{self.loadbalancer.endpoint()}\n")
        print("-" * 88)
        q.ask("Press Enter when you're ready to continue with the demo.")

    def demo_choices(self):
        actions = [
            "Send a GET request to the load balancer endpoint.",
            "Check the health of load balancer targets.",
            "Go to the next part of the demo.",
        ]
        choice = 0
        while choice != 2:
            print("-" * 88)
            print(
                "\nSee the current state of the service by selecting one of the following choices:\n"
            )
            choice = q.choose(
                "\nWhich action would you like to take? ", actions)
            print("-" * 88)
            if choice == 0:
                print("Request:\n")
                print(f"GET http://{self.loadbalancer.endpoint()}")
                response = requests.get(
                    f"http://{self.loadbalancer.endpoint()}")
                print("\nResponse:\n")
                print(f"{response.status_code}")
                if response.headers.get("content-type") == "application/json":
                    pp(response.json())
            elif choice == 1:
                print("\nChecking the health of load balancer targets:\n")
                health = self.loadbalancer.check_target_health()
                for target in health:
                    state = target["TargetHealth"]["State"]
                    print(
                        f"\tTarget {target['Target']['Id']} on port {target['Target']['Port']} is {state}"
                    )
                    if state != "healthy":
                        print(
                            f"\t\t{target['TargetHealth']['Reason']}: {target['TargetHealth']['Description']}\n"
                        )
                print(
                    f"\nNote that it can take a minute or two for the health check to update\n"
                    f"after changes are made.\n")
            elif choice == 2:
                print("\nOkay, let's move on.")
                print("-" * 88)

    def demo(self):
        ssm_only_policy = f"{self.resource_path}/ssm_only_policy.json"

        print("\nResetting parameters to starting values for demo.\n")
        self.param_helper.reset()

        print(
            "\nThis part of the demonstration shows how to toggle different parts of the system\n"
            "to create situations where the web service fails, and shows how using a resilient\n"
            "architecture can keep the web service running in spite of these failures.")
        print("-" * 88)

        print(
            "At the start, the load balancer endpoint returns recommendations and reports that all targets are healthy."
        )
        self.demo_choices()

        print(
            f"The web service running on the EC2 instances gets recommendations by querying a DynamoDB table.\n"
            f"The table name is contained in a Systems Manager parameter named '{self.param_helper.table}'.\n"
            f"To simulate a failure of the recommendation service, let's set this parameter to name a non-existent table.\n")
        self.param_helper.put(self.param_helper.table, "this-is-not-a-table")
        print(
            "\nNow, sending a GET request to the load balancer endpoint returns a failure code. But, the service reports as\n"
            "healthy to the load balancer because shallow health checks don't check for failure of the recommendation service."
        )
        self.demo_choices()

        print(f"Instead of failing when the recommendation service fails, the web service can return a static response.\n"
              f"While this is not a perfect solution, it presents the customer with a somewhat better experience than failure.\n")
        self.param_helper.put(self.param_helper.failure_response, "static")
        print(
            f"\nNow, sending a GET request to the load balancer endpoint returns a static response.\n"
            f"The service still reports as healthy because health checks are still shallow.\n")
        self.demo_choices()

        print("Let's reinstate the recommendation service.\n")
        self.param_helper.put(
            self.param_helper.table,
            self.recommendation.table_name)
        print(
            "\nLet's also substitute bad credentials for one of the instances in the target group so that it can't\n"
            "access the DynamoDB recommendation table.\n")
        self.autoscaler.create_instance_profile(
            ssm_only_policy,
            self.autoscaler.bad_creds_policy_name,
            self.autoscaler.bad_creds_role_name,
            self.autoscaler.bad_creds_profile_name,
            ["AmazonSSMManagedInstanceCore"],
        )
        instances = self.autoscaler.get_instances()
        bad_instance_id = instances[0]
        instance_profile = self.autoscaler.get_instance_profile(
            bad_instance_id)
        print(
            f"\nReplacing the profile for instance {bad_instance_id} with a profile that contains\n"
            f"bad credentials...\n")
        self.autoscaler.replace_instance_profile(
            bad_instance_id,
            self.autoscaler.bad_creds_profile_name,
            instance_profile["AssociationId"],
        )
        print(
            "Now, sending a GET request to the load balancer endpoint returns either a recommendation or a static response,\n"
            "depending on which instance is selected by the load balancer.\n")
        self.demo_choices()

        print(
            "\nLet's implement a deep health check. For this demo, a deep health check tests whether\n"
            "the web service can access the DynamoDB table that it depends on for recommendations. Note that\n"
            "the deep health check is only for ELB routing and not for Auto Scaling instance health.\n"
            "This kind of deep health check is not recommended for Auto Scaling instance health, because it\n"
            "risks accidental termination of all instances in the Auto Scaling group when a dependent service fails.\n")
        print(
            "By implementing deep health checks, the load balancer can detect when one of the instances is failing\n"
            "and take that instance out of rotation.\n")
        self.param_helper.put(self.param_helper.health_check, "deep")
        print(
            f"\nNow, checking target health indicates that the instance with bad credentials ({bad_instance_id})\n"
            f"is unhealthy. Note that it might take a minute or two for the load balancer to detect the unhealthy \n"
            f"instance. Sending a GET request to the load balancer endpoint always returns a recommendation, because\n"
            "the load balancer takes unhealthy instances out of its rotation.\n")
        self.demo_choices()

        print(
            "\nBecause the instances in this demo are controlled by an auto scaler, the simplest way to fix an unhealthy\n"
            "instance is to terminate it and let the auto scaler start a new instance to replace it.\n")
        self.autoscaler.terminate_instance(bad_instance_id)
        print(
            "\nEven while the instance is terminating and the new instance is starting, sending a GET\n"
            "request to the web service continues to get a successful recommendation response because\n"
            "the load balancer routes requests to the healthy instances. After the replacement instance\n"
            "starts and reports as healthy, it is included in the load balancing rotation.\n"
            "\nNote that terminating and replacing an instance typically takes several minutes, during which time you\n"
            "can see the changing health check status until the new instance is running and healthy.\n")
        self.demo_choices()

        print(
            "\nIf the recommendation service fails now, deep health checks mean all instances report as unhealthy.\n"
        )
        self.param_helper.put(self.param_helper.table, "this-is-not-a-table")
        print(
            "\nWhen all instances are unhealthy, the load balancer continues to route requests even to\n"
            "unhealthy instances, allowing them to fail open and return a static response rather than fail\n"
            "closed and report failure to the customer.")
        self.demo_choices()
        self.param_helper.reset()

    def destroy(self):
        print(
            "This concludes the demo of how to build and manage a resilient service.\n"
            "To keep things tidy and to avoid unwanted charges on your account, we can clean up all AWS resources\n"
            "that were created for this demo.")
        if q.ask(
            "Do you want to clean up all demo resources? (y/n) ",
                q.is_yesno):
            self.loadbalancer.delete_load_balancer()
            self.loadbalancer.delete_target_group()
            self.autoscaler.delete_group()
            self.autoscaler.delete_key_pair()
            self.autoscaler.delete_template()
            self.autoscaler.delete_instance_profile(
                self.autoscaler.bad_creds_profile_name,
                self.autoscaler.bad_creds_role_name,
            )
            self.recommendation.destroy()
        else:
            print(
                "Okay, we'll leave the resources intact.\n"
                "Don't forget to delete them when you're done with them or you might incur unexpected charges.")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--action",
        required=True,
        choices=[
            "all",
            "deploy",
            "demo",
            "destroy"],
        help="The action to take for the demo. When 'all' is specified, resources are\n"
        "deployed, the demo is run, and resources are destroyed.",
    )
    parser.add_argument(
        "--resource_path",
        default="../../../workflows/resilient_service/resources",
        help="The path to resource files used by this example, such as IAM policies and\n"
        "instance scripts.",
    )
    args = parser.parse_args()

    print("-" * 88)
    print(
        "Welcome to the demonstration of How to Build and Manage a Resilient Service!"
    )
    print("-" * 88)

    prefix = "doc-example-resilience"
    recommendation = RecommendationService.from_client(
        "doc-example-recommendation-service"
    )
    autoscaler = AutoScaler.from_client(prefix)
    loadbalancer = LoadBalancer.from_client(prefix)
    param_helper = ParameterHelper.from_client(recommendation.table_name)
    runner = Runner(
        args.resource_path,
        recommendation,
        autoscaler,
        loadbalancer,
        param_helper)
    actions = [
        args.action] if args.action != "all" else [
        "deploy", "demo", "destroy"]
    for action in actions:
        if action == "deploy":
            runner.deploy()
        elif action == "demo":
            runner.demo()
        elif action == "destroy":
            runner.destroy()

    print("-" * 88)
    print("Thanks for watching!")
    print("-" * 88)


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(levelname)s: %(message)s")
    main()
# snippet-end:[python.example_code.workflow.ResilientService_Runner]
